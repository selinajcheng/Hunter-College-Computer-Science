@book{sicp,
  author    = {Harold Abelson and Gerald Jay Sussman and Julie Sussman},
  title     = {Structure and Interpretation of Computer Programs},
  publisher = {MIT Press},
  year      = {1996},
  edition   = {2}
}

@inproceedings{10.1145/3278721.3278770,
    author = {Kim, Richard and Kleiman-Weiner, Max and Abeliuk, Andr\'{e}s and Awad, Edmond and Dsouza, Sohan and Tenenbaum, Joshua B. and Rahwan, Iyad},
    title = {A Computational Model of Commonsense Moral Decision Making},
    year = {2018},
    isbn = {9781450360128},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/3278721.3278770},
    doi = {10.1145/3278721.3278770},
    abstract = {We introduce a computational model for building moral autonomous vehicles by learning and generalizing from human moral judgments. We draw on a cognitively inspired model of how people and young children learn moral theories from sparse and noisy data and integrate observations made from different people in different groups. The problem of moral learning for autonomous vehicles is cast as learning how to weigh the different features of the dilemma using utility calculus, with the goal of making these trade-offs reflect how people make them in a wide variety of moral dilemma. By modeling the structures of individuals and groups in a hierarchical Bayesian model, we show that an individual's moral values -- as well as a group's shared values -- can be inferred from sparse and noisy data. We evaluate our approach with data from the Moral Machine, a web application that collects human judgments on moral dilemmas involving autonomous vehicles, and show that the model rapidly and accurately infers people's preferences and can predict the difficulty of moral dilemmas from limited data.},
    booktitle = {Proceedings of the 2018 AAAI/ACM Conference on AI, Ethics, and Society},
    pages = {197–203},
    numpages = {7},
    keywords = {artificial intelligence, bayesian inference, machine ethics, moral learning},
    location = {New Orleans, LA, USA},
    series = {AIES '18}
}

@misc{kim2018computationalmodelcommonsensemoral,
      title={A Computational Model of Commonsense Moral Decision Making}, 
      author={Richard Kim and Max Kleiman-Weiner and Andres Abeliuk and Edmond Awad and Sohan Dsouza and Josh Tenenbaum and Iyad Rahwan},
      year={2018},
      eprint={1801.04346},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/1801.04346}, 
}

@article{622436,
    author = {Awad and Dsouza and Kim and Schulz and Henrich and Shariff and J. Bonnefon and Rahwan},
    title = {The Moral Machine Experiment},
    year = {2018},
    journal = {Nature},
    volume = {563},
    pages = {59-64},
    url = {https://www.nature.com/articles/s41586-018-0637-6},
    language = {eng},
}

@InCollection{Amarel1968,
    author = 	 {Amarel, Saul},
    title = 	 {On Representations of Problems of Reasoning about Actions},
    booktitle = 	 {Machine Intelligence 3},
    pages = 	 {131--171},
    publisher =    {American Elsevier Publisher},
    year = 	 {1968},
    editor =       {Michie, Donald}
}

@article{doi:10.1126/science.134.3495.2011,
    author = {Allen Newell  and Herbert A. Simon },
    title = {Computer Simulation of Human Thinking},
    journal = {Science},
    volume = {134},
    number = {3495},
    pages = {2011-2017},
    year = {1961},
    doi = {10.1126/science.134.3495.2011},
    URL = {https://www.science.org/doi/abs/10.1126/science.134.3495.2011},
    eprint = {https://www.science.org/doi/pdf/10.1126/science.134.3495.2011}
}

@article{doi:10.1126/science.1192788,
    author = {Joshua B. Tenenbaum  and Charles Kemp  and Thomas L. Griffiths  and Noah D. Goodman },
    title = {How to Grow a Mind: Statistics, Structure, and Abstraction},
    journal = {Science},
    volume = {331},
    number = {6022},
    pages = {1279-1285},
    year = {2011},
    doi = {10.1126/science.1192788},
    URL = {https://www.science.org/doi/abs/10.1126/science.1192788},
    eprint = {https://www.science.org/doi/pdf/10.1126/science.1192788},
    abstract = {In coming to understand the world—in learning concepts, acquiring language, and grasping causal relations—our minds make inferences that appear to go far beyond the data available. How do we do it? This review describes recent approaches to reverse-engineering human learning and cognitive development and, in parallel, engineering more humanlike machine learning systems. Computational models that perform probabilistic inference over hierarchies of flexibly structured representations can address some of the deepest questions about the nature and origins of human thought: How does abstract knowledge guide learning and reasoning from sparse data? What forms does our knowledge take, across different domains and tasks? And how is that abstract knowledge itself acquired?}
}

@article{GRIFFITHS2010357,
    title = {Probabilistic models of cognition: exploring representations and inductive biases},
    journal = {Trends in Cognitive Sciences},
    volume = {14},
    number = {8},
    pages = {357-364},
    year = {2010},
    issn = {1364-6613},
    doi = {https://doi.org/10.1016/j.tics.2010.05.004},
    url = {https://www.sciencedirect.com/science/article/pii/S1364661310001129},
    author = {Thomas L. Griffiths and Nick Chater and Charles Kemp and Amy Perfors and Joshua B. Tenenbaum},
    abstract = {Cognitive science aims to reverse-engineer the mind, and many of the engineering challenges the mind faces involve induction. The probabilistic approach to modeling cognition begins by identifying ideal solutions to these inductive problems. Mental processes are then modeled using algorithms for approximating these solutions, and neural processes are viewed as mechanisms for implementing these algorithms, with the result being a top-down analysis of cognition starting with the function of cognitive processes. Typical connectionist models, by contrast, follow a bottom-up approach, beginning with a characterization of neural mechanisms and exploring what macro-level functional phenomena might emerge. We argue that the top-down approach yields greater flexibility for exploring the representations and inductive biases that underlie human cognition.}
}

@article{NELL,
    author = {Mitchell, T. and Cohen, W. and Hruschka, E. and Talukdar, P. and Yang, B. and Betteridge, J. and Carlson, A. and Dalvi, B. and Gardner, M. and Kisiel, B. and Krishnamurthy, J. and Lao, N. and Mazaitis, K. and Mohamed, T. and Nakashole, N. and Platanios, E. and Ritter, A. and Samadi, M. and Settles, B. and Wang, R. and Wijaya, D. and Gupta, A. and Chen, X. and Saparov, A. and Greaves, M. and Welling, J.},
    title = {Never-ending learning},
    year = {2018},
    issue_date = {May 2018},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    volume = {61},
    number = {5},
    issn = {0001-0782},
    url = {https://doi.org/10.1145/3191513},
    doi = {10.1145/3191513},
    abstract = {Whereas people learn many different types of knowledge from diverse experiences over many years, and become better learners over time, most current machine learning systems are much more narrow, learning just a single function or data model based on statistical analysis of a single data set. We suggest that people learn better than computers precisely because of this difference, and we suggest a key direction for machine learning research is to develop software architectures that enable intelligent agents to also learn many types of knowledge, continuously over many years, and to become better learners over time. In this paper we define more precisely this never-ending learning paradigm for machine learning, and we present one case study: the Never-Ending Language Learner (NELL), which achieves a number of the desired properties of a never-ending learner. NELL has been learning to read the Web 24hrs/day since January 2010, and so far has acquired a knowledge base with 120mn diverse, confidence-weighted beliefs (e.g., servedWith(tea,biscuits)), while learning thousands of interrelated functions that continually improve its reading competence over time. NELL has also learned to reason over its knowledge base to infer new beliefs it has not yet read from those it has, and NELL is inventing new relational predicates to extend the ontology it uses to represent beliefs. We describe the design of NELL, experimental results illustrating its behavior, and discuss both its successes and shortcomings as a case study in never-ending learning. NELL can be tracked online at http://rtw.ml.cmu.edu, and followed on Twitter at @CMUNELL.},
    journal = {Commun. ACM},
    month = apr,
    pages = {103–115},
    numpages = {13}
}

@INPROCEEDINGS{NEIL,
    author={Chen, Xinlei and Shrivastava, Abhinav and Gupta, Abhinav},
    booktitle={2013 IEEE International Conference on Computer Vision}, 
    title={NEIL: Extracting Visual Knowledge from Web Data}, 
    year={2013},
    volume={},
    number={},
    pages={1409-1416},
    keywords={Visualization;Detectors;Semantics;Data mining;Computers;Knowledge based systems;Semisupervised learning;never ending learning;visual knowledge base;common sense relationships;macro vision;object detection;scene classification;attributes;semi-supervised learning},
    doi={10.1109/ICCV.2013.178}
}

@inproceedings{Architecture,
    author = {Carlson, Andrew and Betteridge, Justin and Kisiel, Bryan and Settles, Burr and Hruschka, Estevam R. and Mitchell, Tom M.},
    title = {Toward an architecture for never-ending language learning},
    year = {2010},
    publisher = {AAAI Press},
    abstract = {We consider here the problem of building a never-ending language learner; that is, an intelligent computer agent that runs forever and that each day must (1) extract, or read, information from the web to populate a growing structured knowledge base, and (2) learn to perform this task better than on the previous day. In particular, we propose an approach and a set of design principles for such an agent, describe a partial implementation of such a system that has already learned to extract a knowledge base containing over 242,000 beliefs with an estimated precision of 74\% after running for 67 days, and discuss lessons learned from this preliminary attempt to build a never-ending learning agent.},
    booktitle = {Proceedings of the Twenty-Fourth AAAI Conference on Artificial Intelligence},
    pages = {1306–1313},
    numpages = {8},
    location = {Atlanta, Georgia},
    series = {AAAI'10}
}

@inproceedings{Curriculum,
    author = {Bengio, Yoshua and Louradour, J\'{e}r\^{o}me and Collobert, Ronan and Weston, Jason},
    title = {Curriculum learning},
    year = {2009},
    isbn = {9781605585161},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/1553374.1553380},
    doi = {10.1145/1553374.1553380},
    abstract = {Humans and animals learn much better when the examples are not randomly presented but organized in a meaningful order which illustrates gradually more concepts, and gradually more complex ones. Here, we formalize such training strategies in the context of machine learning, and call them "curriculum learning". In the context of recent research studying the difficulty of training in the presence of non-convex training criteria (for deep deterministic and stochastic neural networks), we explore curriculum learning in various set-ups. The experiments show that significant improvements in generalization can be achieved. We hypothesize that curriculum learning has both an effect on the speed of convergence of the training process to a minimum and, in the case of non-convex criteria, on the quality of the local minima obtained: curriculum learning can be seen as a particular form of continuation method (a general strategy for global optimization of non-convex functions).},
    booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
    pages = {41–48},
    numpages = {8},
    location = {Montreal, Quebec, Canada},
    series = {ICML '09}
}

@misc{gao2025agent4edugeneratinglearnerresponse,
    title={Agent4Edu: Generating Learner Response Data by Generative Agents for Intelligent Education Systems}, 
    author={Weibo Gao and Qi Liu and Linan Yue and Fangzhou Yao and Rui Lv and Zheng Zhang and Hao Wang and Zhenya Huang},
    year={2025},
    eprint={2501.10332},
    archivePrefix={arXiv},
    primaryClass={cs.CY},
    url={https://arxiv.org/abs/2501.10332}, 
}

@misc{hall2025pitfallssecurityobscuritymean,
    title={The Pitfalls of "Security by Obscurity" And What They Mean for Transparent AI}, 
    author={Peter Hall and Olivia Mundahl and Sunoo Park},
    year={2025},
    eprint={2501.18669},
    archivePrefix={arXiv},
    primaryClass={cs.CR},
    url={https://arxiv.org/abs/2501.18669}, 
}

@misc{gundersen2024unreasonableeffectivenessopenscience,
    title={The Unreasonable Effectiveness of Open Science in AI: A Replication Study}, 
    author={Odd Erik Gundersen and Odd Cappelen and Martin Mølnå and Nicklas Grimstad Nilsen},
    year={2024},
    eprint={2412.17859},
    archivePrefix={arXiv},
    primaryClass={cs.AI},
    url={https://arxiv.org/abs/2412.17859}, 
}

@inproceedings{10.5555/3692070.3694580,
    author = {Zhao, Dora and Andrews, Jerone T. A. and Papakyriakopoulos, Orestis and Xiang, Alice},
    title = {Position: measure dataset diversity, don't just claim it},
    year = {2024},
    publisher = {JMLR.org},
    abstract = {Machine learning (ML) datasets, often perceived as neutral, inherently encapsulate abstract and disputed social constructs. Dataset curators frequently employ value-laden terms such as diversity, bias, and quality to characterize datasets. Despite their prevalence, these terms lack clear definitions and validation. Our research explores the implications of this issue by analyzing "diversity" across 135 image and text datasets. Drawing from social sciences, we apply principles from measurement theory to identify considerations and offer recommendations for conceptualizing, operationalizing, and evaluating diversity in datasets. Our findings have broader implications for ML research, advocating for a more nuanced and precise approach to handling value-laden properties in dataset construction.},
    booktitle = {Proceedings of the 41st International Conference on Machine Learning},
    articleno = {2510},
    numpages = {30},
    location = {Vienna, Austria},
    series = {ICML'24}
}

@misc{gundersen2023sourcesirreproducibilitymachinelearning,
    title={Sources of Irreproducibility in Machine Learning: A Review}, 
    author={Odd Erik Gundersen and Kevin Coakley and Christine Kirkpatrick and Yolanda Gil},
    year={2023},
    eprint={2204.07610},
    archivePrefix={arXiv},
    primaryClass={cs.LG},
    url={https://arxiv.org/abs/2204.07610}, 
}

@misc{reid2025doesgptreallyit,
    title={Does GPT Really Get It? A Hierarchical Scale to Quantify Human vs AI's Understanding of Algorithms}, 
    author={Mirabel Reid and Santosh S. Vempala},
    year={2025},
    eprint={2406.14722},
    archivePrefix={arXiv},
    primaryClass={cs.AI},
    url={https://arxiv.org/abs/2406.14722}, 
}

@inproceedings{Savelka_2023, series={ICER 2023},
    title={Thrilled by Your Progress! Large Language Models (GPT-4) No Longer Struggle to Pass Assessments in Higher Education Programming Courses},
    url={http://dx.doi.org/10.1145/3568813.3600142},
    DOI={10.1145/3568813.3600142},
    booktitle={Proceedings of the 2023 ACM Conference on International Computing Education Research V.1},
    publisher={ACM},
    author={Savelka, Jaromir and Agarwal, Arav and An, Marshall and Bogart, Chris and Sakr, Majd},
    year={2023},
    month=aug, pages={78–92},
    collection={ICER 2023} 
}

@misc{huang2025perceptionguidedjailbreaktexttoimagemodels,
      title={Perception-guided Jailbreak against Text-to-Image Models}, 
      author={Yihao Huang and Le Liang and Tianlin Li and Xiaojun Jia and Run Wang and Weikai Miao and Geguang Pu and Yang Liu},
      year={2025},
      eprint={2408.10848},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2408.10848}, 
}
@misc{reid2025doesgptreallyit,
      title={Does GPT Really Get It? A Hierarchical Scale to Quantify Human vs AI's Understanding of Algorithms}, 
      author={Mirabel Reid and Santosh S. Vempala},
      year={2025},
      eprint={2406.14722},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2406.14722}, 
}

@online{gfg_black_white_testing,
    author       = {GeeksforGeeks},
    title        = {Differences between Black Box Testing and White Box Testing},
    year         = {2025},
    url          = {https://www.geeksforgeeks.org/differences-between-black-box-testing-vs-white-box-testing/},
    note         = {Accessed: 2025-04-20}
}

@software{huang2025pgjcode,
    author       = {Ling Liang},
    title        = {Perception-guided Jailbreak (PGJ)},
    version      = {1.0},
    date         = {2025-04-20},
    url          = {https://github.com/LeLiang-SJTU/Perception-guided-Jailbreak-},
    organization = {GitHub}
}

@inproceedings{NEURIPS2024_6f11132f,
    author = {Ma, Yizhuo and Pang, Shanmin and Guo, Qi and Wei, Tianyu and Guo, Qing},
    booktitle = {Advances in Neural Information Processing Systems},
    editor = {A. Globerson and L. Mackey and D. Belgrave and A. Fan and U. Paquet and J. Tomczak and C. Zhang},
    pages = {60335--60358},
    publisher = {Curran Associates, Inc.},
    title = {ColJailBreak: Collaborative Generation and Editing for Jailbreaking Text-to-Image Deep Generation},
    url = {https://proceedings.neurips.cc/paper_files/paper/2024/file/6f11132f6ecbbcafafdf6decfc98f7be-Paper-Conference.pdf},
    volume = {37},
    year = {2024}
}

@misc{huang2025perceptionguidedjailbreaktexttoimagemodels,
    title={Perception-guided Jailbreak against Text-to-Image Models}, 
    author={Yihao Huang and Le Liang and Tianlin Li and Xiaojun Jia and Run Wang and Weikai Miao and Geguang Pu and Yang Liu},
    year={2025},
    eprint={2408.10848},
    archivePrefix={arXiv},
    primaryClass={cs.CV},
    url={https://arxiv.org/abs/2408.10848}, 
}

@misc{reid2025doesgptreallygetit,
    title={Does GPT Really Get It? A Hierarchical Scale to Quantify Human vs AI's Understanding of Algorithms}, 
    author={Mirabel Reid and Santosh S. Vempala},
    year={2025},
    eprint={2406.14722},
    archivePrefix={arXiv},
    primaryClass={cs.AI},
    url={https://arxiv.org/abs/2406.14722}, 
}

@online{gfg_black_white_testing,
    author       = {GeeksforGeeks},
    title        = {Differences between Black Box Testing and White Box Testing},
    year         = {2025},
    url          = {https://www.geeksforgeeks.org/differences-between-black-box-testing-vs-white-box-testing/},
    note         = {Accessed: 2025-04-20}
}

@software{huang2025pgjcode,
    author       = {Ling Liang},
    title        = {Perception-guided Jailbreak (PGJ)},
    version      = {1.0},
    date         = {2025-04-20},
    url          = {https://github.com/LeLiang-SJTU/Perception-guided-Jailbreak-},
    organization = {GitHub}
}

@inproceedings{ma2024coljailbreak,
    author = {Ma, Yizhuo and Pang, Shanmin and Guo, Qi and Wei, Tianyu and Guo, Qing},
    booktitle = {Advances in Neural Information Processing Systems},
    editor = {A. Globerson and L. Mackey and D. Belgrave and A. Fan and U. Paquet and J. Tomczak and C. Zhang},
    pages = {60335--60358},
    publisher = {Curran Associates, Inc.},
    title = {ColJailBreak: Collaborative Generation and Editing for Jailbreaking Text-to-Image Deep Generation},
    url = {https://proceedings.neurips.cc/paper_files/paper/2024/file/6f11132f6ecbbcafafdf6decfc98f7be-Paper-Conference.pdf},
    volume = {37},
    year = {2024}
}

@misc{tsai2024ringabellreliableconceptremoval,
    title={Ring-A-Bell! How Reliable are Concept Removal Methods for Diffusion Models?}, 
    author={Yu-Lin Tsai and Chia-Yi Hsu and Chulin Xie and Chih-Hsun Lin and Jia-You Chen and Bo Li and Pin-Yu Chen and Chia-Mu Yu and Chun-Ying Huang},
    year={2024},
    eprint={2310.10012},
    archivePrefix={arXiv},
    primaryClass={cs.LG},
    url={https://arxiv.org/abs/2310.10012}, 
}

@inproceedings{NEURIPS2023_Dai_InstructBLIP,
    author = {Dai, Wenliang and Li, Junnan and LI, DONGXU and Tiong, Anthony and Zhao, Junqi and Wang, Weisheng and Li, Boyang and Fung, Pascale N and Hoi, Steven},
    booktitle = {Advances in Neural Information Processing Systems},
    editor = {A. Oh and T. Naumann and A. Globerson and K. Saenko and M. Hardt and S. Levine},
    pages = {49250--49267},
    publisher = {Curran Associates, Inc.},
    title = {InstructBLIP: Towards General-purpose Vision-Language Models with Instruction Tuning},
    url = {https://proceedings.neurips.cc/paper_files/paper/2023/file/9a6a435e75419a836fe47ab6793623e6-Paper-Conference.pdf},
    volume = {36},
    year = {2023}
}

@inproceedings{li2023blip2bootstrappinglanguageimagepretraining,
    author = {Li, Junnan and Li, Dongxu and Savarese, Silvio and Hoi, Steven},
    title = {BLIP-2: bootstrapping language-image pre-training with frozen image encoders and large language models},
    year = {2023},
    publisher = {JMLR.org},
    abstract = {The cost of vision-and-language pre-training has become increasingly prohibitive due to end-to-end training of large-scale models. This paper proposes BLIP-2, a generic and efficient pretraining strategy that bootstraps vision-language pre-training from off-the-shelf frozen pretrained image encoders and frozen large language models. BLIP-2 bridges the modality gap with a lightweight Querying Transformer, which is pretrained in two stages. The first stage bootstraps vision-language representation learning from a frozen image encoder. The second stage bootstraps vision-to-language generative learning from a frozen language model. BLIP-2 achieves state-of-the-art performance on various vision-language tasks, despite having significantly fewer trainable parameters than existing methods. For example, our model outperforms Flamingo80B by 8.7\% on zero-shot VQAv2 with 54x fewer trainable parameters. We also demonstrate the model's capabilities of zero-shot image-to-text generation that can follow natural language instructions.},
    booktitle = {Proceedings of the 40th International Conference on Machine Learning},
    articleno = {814},
    numpages = {13},
    location = {Honolulu, Hawaii, USA},
    series = {ICML'23}
}

@misc{li2022blipbootstrappinglanguageimagepretraining,
    title={BLIP: Bootstrapping Language-Image Pre-training for Unified Vision-Language Understanding and Generation}, 
    author={Junnan Li and Dongxu Li and Caiming Xiong and Steven Hoi},
    year={2022},
    eprint={2201.12086},
    archivePrefix={arXiv},
    primaryClass={cs.CV},
    url={https://arxiv.org/abs/2201.12086}, 
}

@misc{labenz2023ai,
    author = {Junnan Li and Dongxu Li and Nathan Labenz},
    title = {The {AI} Multimodal Revolution with Junnan Li and Dongxu Li of {BLIP} \& {BLIP2}},
    howpublished = {YouTube},
    publisher = {The Cognitive Revolution: How AI Changes Everything},
    year = {2023},
    month = {March},
    url = {https://youtu.be/zTr5vDjEy2I?si=ULWMQMd0aSiQDi7L},
    note = {Interviewed by Nathan Labenz; Published on Mar 9, 2023}
}

@misc{hahmzhang2024instructblip,
    author = {Seung Hyung Hahm and Chunhui Zhang},
    title = {Instruct{B}LIP - 5-Minute Student Presentation},
    howpublished = {YouTube},
    year = {2024},
    month = {October},
    publisher = {Yu-Wing Tai},
    url = {https://youtu.be/GMyS3SRgwxw?si=1PiDs4j4_zrfJ_sc},
    note = {5-Minute Student Presentation @ Dartmouth, COSC89/189 Fall 2024 Multi-Modalities Generative AI. Published on Oct 22, 2024},
}

@online{geeksforgeeks2023mtl,
    author       = {GeeksforGeeks},
    title        = {Introduction to Multi-Task Learning(MTL) for Deep Learning},
    year         = {2023},
    url          = {https://www.geeksforgeeks.org/introduction-to-multi-task-learningmtl-for-deep-learning/},
    note         = {Last updated: January 19, 2023},
    urldate      = {2025-05-16}
}

@misc{han2022cropmixsamplingrichinput,
    title={CropMix: Sampling a Rich Input Distribution via Multi-Scale Cropping}, 
    author={Junlin Han and Lars Petersson and Hongdong Li and Ian Reid},
    year={2022},
    eprint={2205.15955},
    archivePrefix={arXiv},
    primaryClass={cs.CV},
    url={https://arxiv.org/abs/2205.15955}, 
}